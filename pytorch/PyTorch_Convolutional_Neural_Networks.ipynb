{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_Convolutional_Neural_Networks",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "is5xY4FQPaH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYoAygSCRWv-",
        "colab_type": "text"
      },
      "source": [
        "### Create Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPRSrY7kRIqT",
        "colab_type": "code",
        "outputId": "3989a7cd-7616-4aa2-916f-34ff03d1e1d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    #1 input image channel channel, filter size of 6, 3x3 square convolution kernel\n",
        "    self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 3) \n",
        "    self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 16, kernel_size = 3)\n",
        "\n",
        "    #an affine operation y = Mx + b. Simply, Dense layer of Fully Connected layer\n",
        "    #in_features = 6x6 (image_size) * 16 (output channels from previous layers)\n",
        "    self.fc1 = nn.Linear(in_features = 16 * 6 * 6, out_features = 120) #out_features ~= nodes in Tensorflow\n",
        "    self.fc2 = nn.Linear(in_features = 120, out_features = 84)\n",
        "    self.fc3 = nn.Linear(in_features = 84, out_features = 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "      #Max pooling over\n",
        "      x = F.max_pool2d(F.relu(self.conv1(x)), kernel_size = (2,2))\n",
        "      #If the size if a square you can only specify a signle number\n",
        "      x = F.max_pool2d(F.relu(self.conv2(x)), kernel_size = (2,2))\n",
        "      x = torch.flatten(x, start_dim = 1, end_dim = -1) #Torch supports mini-batch only\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = self.fc3(x)\n",
        "      return x\n",
        "  def num_flat_features(self, x):\n",
        "    size = x.size()[1:] #all dimension except the batch dimension\n",
        "    num_features = 1\n",
        "    for s in size:\n",
        "      num_features *= s\n",
        "    return num_features \n",
        "net = Net()\n",
        "print(net)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H9kRO4SZgya",
        "colab_type": "text"
      },
      "source": [
        "#### Get trainable parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GYYzZd_V-_n",
        "colab_type": "code",
        "outputId": "a139e5b9-25c8-4a7d-fbee-00a72a342a1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "params = list(net.parameters())\n",
        "print(len(params))\n",
        "print(params[0].size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "torch.Size([6, 1, 3, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoRL-KO1Z19J",
        "colab_type": "text"
      },
      "source": [
        "#### Random inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPRL6pzoZnkr",
        "colab_type": "code",
        "outputId": "68fe7c06-fab3-4477-9015-2b9ecdaf9c1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "input = torch.randn(1,1,32,32)\n",
        "out = net(input)\n",
        "print(out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.4819e-04,  2.0977e-02, -1.0035e-01,  9.8798e-02, -5.3361e-02,\n",
            "          1.6321e-01,  5.7239e-02,  2.2307e-02, -1.1789e-01, -1.1450e-01]],\n",
            "       grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFb6coAwaD7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.zero_grad()\n",
        "out.backward(torch.randn(1,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ti8_f2HZ1OE",
        "colab_type": "text"
      },
      "source": [
        "#### Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTylLJIrcyz3",
        "colab_type": "code",
        "outputId": "646016fe-e8b4-4a86-c459-b3a28a662fe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "output = net(input)\n",
        "target = torch.randn(10) #dummy target, for example\n",
        "target = target.expand_as(output)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "loss = criterion(output, target)\n",
        "print(loss)\n",
        "print(loss.backward)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.0326, grad_fn=<MseLossBackward>)\n",
            "<bound method Tensor.backward of tensor(1.0326, grad_fn=<MseLossBackward>)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY6XPeubc_jH",
        "colab_type": "code",
        "outputId": "012082fb-fed4-45b6-d51e-0e7cb700ff20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "#print loss in backward_direction\n",
        "print(loss.grad_fn)\n",
        "print(loss.grad_fn.next_functions[0][0]) #Linear\n",
        "print(loss.grad_fn.next_functions[0][0].next_functions[0][0]) #ReLU"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<MseLossBackward object at 0x7fc9a9e554e0>\n",
            "<AddmmBackward object at 0x7fc9a9e55630>\n",
            "<AccumulateGrad object at 0x7fc9a9e554e0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnXv1tted-Bq",
        "colab_type": "code",
        "outputId": "ef2f6df6-16eb-43e5-e94b-3f75f28f8a49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "net.zero_grad()\n",
        "print('conv1.bias.grad before backward')\n",
        "print(net.conv1.bias.grad)\n",
        "\n",
        "loss.backward()\n",
        "print('conv1.bias.grad before backward')\n",
        "print(net.conv1.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.bias.grad before backward\n",
            "None\n",
            "conv1.bias.grad before backward\n",
            "tensor([-0.0153,  0.0094,  0.0141,  0.0046,  0.0079, -0.0006])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9OF1usIhBf6",
        "colab_type": "text"
      },
      "source": [
        "#### Update weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyvXQKv8hAkh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.01\n",
        "for f in net.parameters():\n",
        "  f.data.sub_(f.grad.data * learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY4p6zyKeJbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "#create optimizer\n",
        "optimizer = optim.SGD(net.parameters(), lr = 0.01)\n",
        "\n",
        "#in training loop\n",
        "optimizer.zero_grad() #zero the gradient buffers\n",
        "outut = net(input)\n",
        "loss = criterion(output, target)\n",
        "loss.backward()\n",
        "optimizer.step() #Does the update"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Roa5cJjmhknb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}